#!rnn.py

def summary(name, x):
  """
  :param str name:
  :param tf.Tensor x: (batch,time,feature)
  """
  from returnn.tf.compat import v1 as tf
  # tf.summary.image wants [batch_size, height,  width, channels],
  # we have (batch, time, feature).
  img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
  img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
  tf.summary.image(name, img, max_outputs=10)
  tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
  mean = tf.reduce_mean(x)
  tf.summary.scalar("%s_mean" % name, mean)
  stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
  tf.summary.scalar("%s_stddev" % name, stddev)
  tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))

def _mask(x, batch_axis, axis, pos, max_amount):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int batch_axis:
  :param int axis:
  :param tf.Tensor pos: (batch,)
  :param int|tf.Tensor max_amount: inclusive
  """
  from returnn.tf.compat import v1 as tf
  ndim = x.get_shape().ndims
  n_batch = tf.shape(x)[batch_axis]
  dim = tf.shape(x)[axis]
  amount = tf.random_uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
  pos2 = tf.minimum(pos + amount, dim)
  idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
  pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
  pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
  cond = tf.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
  if batch_axis > axis:
      cond = tf.transpose(cond)  # (dim,batch)
  cond = tf.reshape(cond, [tf.shape(x)[i] if i in (batch_axis, axis) else 1 for i in range(ndim)])
  from TFUtil import where_bc
  x = where_bc(cond, 0.0, x)
  return x

def random_mask(x, batch_axis, axis, min_num, max_num, max_dims):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int batch_axis:
  :param int axis:
  :param int|tf.Tensor min_num:
  :param int|tf.Tensor max_num: inclusive
  :param int|tf.Tensor max_dims: inclusive
  """
  from returnn.tf.compat import v1 as tf
  n_batch = tf.shape(x)[batch_axis]
  if isinstance(min_num, int) and isinstance(max_num, int) and min_num == max_num:
      num = min_num
  else:
      num = tf.random_uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
  # https://github.com/tensorflow/tensorflow/issues/9260
  # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
  z = -tf.log(-tf.log(tf.random_uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
  _, indices = tf.nn.top_k(z, num if isinstance(num, int) else tf.reduce_max(num))
  # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
  # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
  if isinstance(num, int):
      for i in range(num):
          x = _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims)
  else:
      _, x = tf.while_loop(
          cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
          body=lambda i, x: (
              i + 1,
              tf.where(
                  tf.less(i, num),
                  _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims),
                  x)),
          loop_vars=(0, x))
  return x

def transform(data, network, time_factor=1):
  x = data.placeholder
  from returnn.tf.compat import v1 as tf
  # summary("features", x)
  step = network.global_train_step
  step1 = tf.where(tf.greater_equal(step, 1000), 1, 0)
  step2 = tf.where(tf.greater_equal(step, 2000), 1, 0)
  def get_masked():
      x_masked = x
      x_masked = random_mask(
        x_masked, batch_axis=data.batch_dim_axis, axis=data.time_dim_axis,
        min_num=step1 + step2, max_num=tf.maximum(tf.shape(x)[data.time_dim_axis] // 100, 2) * (1 + step1 + step2 * 2),
        max_dims=20 // time_factor)
      x_masked = random_mask(
        x_masked, batch_axis=data.batch_dim_axis, axis=data.feature_dim_axis,
        min_num=step1 + step2, max_num=2 + step1 + step2 * 2,
        max_dims=data.dim // 5)
      #summary("features_mask", x_masked)
      return x_masked
  x = network.cond_on_train(get_masked, lambda: x)
  return x


AttNumHeads = 1
EncValuePerHeadDim = 2048
accum_grad_multiple_step = 1
adam = True
batch_size = 10000
batching = 'random'
cache_size = '0'
cleanup_old_models = True
cleanup_old_models  = {'keep': [80, 100, 160, 170, 180, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200]}
debug_mode = False
debug_print_layer_output_template = True
dev = { 'bpe': { 'bpe_file': '/u/zeineldeen/setups/switchboard/2021-04-17--long-train/work/bpe/train/ReturnnTrainBpeJob.oCWOav11gY6s/output/bpe.codes',
           'seq_postfix': [0],
           'unknown_label': None,
           'vocab_file': '/u/zeineldeen/setups/switchboard/2021-04-17--long-train/work/bpe/train/ReturnnTrainBpeJob.oCWOav11gY6s/output/bpe.vocab'},
  'class': 'ExternSprintDataset',
  'estimated_num_seqs': 3000,
  'input_stddev': 3.0,
  'partitionEpoch': 1,
  'sprintConfigStr': [ '--config=/u/zeineldeen/setups/switchboard/2020-07-16--phon-att-sis/dependencies/rasr_configs/training.config',
                       '--*.corpus.file=`cf /work/asr3/irie/data/switchboard/corpora/train.corpus.gz`',
                       '--*.corpus.segments.file=`cf /u/zeineldeen/setups/switchboard/2020-01-21--att-phon/dependencies/seg_cv_head3000`',
                       '--*.corpus.segment-order-shuffle=true',
                       '--*.segment-order-sort-by-time-length=true',
                       '--*.segment-order-sort-by-time-length-chunk-size=-1',
                       '--*.feature-cache-path=`cf /u/tuske/work/ASR/switchboard/feature.extraction/gt40_40/data/gt.train.bundle`',
                       '--*.log-channel.file=cv.sprint.log',
                       '--*.window-size=1'],
  'sprintTrainerExecPath': '/u/zhou/rasr-dev/arch/linux-x86_64-standard/nn-trainer.linux-x86_64-standard'}
device = 'gpu'
eval_datasets = { 'devtrain': { 'bpe': { 'bpe_file': '/u/zeineldeen/setups/switchboard/2021-04-17--long-train/work/bpe/train/ReturnnTrainBpeJob.oCWOav11gY6s/output/bpe.codes',
                         'seq_postfix': [0],
                         'unknown_label': None,
                         'vocab_file': '/u/zeineldeen/setups/switchboard/2021-04-17--long-train/work/bpe/train/ReturnnTrainBpeJob.oCWOav11gY6s/output/bpe.vocab'},
                'class': 'ExternSprintDataset',
                'estimated_num_seqs': 3000,
                'input_stddev': 3.0,
                'partitionEpoch': 1,
                'sprintConfigStr': [ '--config=/u/zeineldeen/setups/switchboard/2020-07-16--phon-att-sis/dependencies/rasr_configs/training.config',
                                     '--*.corpus.file=`cf /work/asr3/irie/data/switchboard/corpora/train.corpus.gz`',
                                     '--*.corpus.segments.file=`cf '
                                     '/u/zeineldeen/setups/switchboard/2020-01-21--att-phon/dependencies/seg_train_head3000`',
                                     '--*.corpus.segment-order-shuffle=true',
                                     '--*.segment-order-sort-by-time-length=true',
                                     '--*.segment-order-sort-by-time-length-chunk-size=-1',
                                     '--*.feature-cache-path=`cf /u/tuske/work/ASR/switchboard/feature.extraction/gt40_40/data/gt.train.bundle`',
                                     '--*.log-channel.file=devtrain.sprint.log',
                                     '--*.window-size=1'],
                'sprintTrainerExecPath': '/u/zhou/rasr-dev/arch/linux-x86_64-standard/nn-trainer.linux-x86_64-standard'}}
extern_data = {'bpe': {'dim': 534, 'shape': (None,), 'sparse': True}, 'data': {'dim': 40, 'shape': (None, 40)}}
gradient_clip = 0
gradient_noise = 0.0
learning_rate = 0.0008
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
learning_rate_file = 'learning_rates'
learning_rates = None
log = ['./crnn.log']
log_batch_size = True
log_verbosity = 5
max_seqs = 200
min_learning_rate = 2e-05
model = '/u/zeineldeen/setups/switchboard/2021-04-17--long-train/work/crnn/training/CRNNTrainingJob.lvuDwZGutQge/output/models/epoch'
multiprocessing = True
network = { 'conv0': { 'L2': 0.0001,
             'activation': None,
             'class': 'conv',
             'filter_size': (3, 3),
             'from': 'source0',
             'n_out': 32,
             'padding': 'same',
             'with_bias': True},
  'conv0p': {'class': 'pool', 'from': 'conv0', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv1': { 'L2': 0.0001,
             'activation': None,
             'class': 'conv',
             'filter_size': (3, 3),
             'from': 'conv0p',
             'n_out': 32,
             'padding': 'same',
             'with_bias': True},
  'conv1p': {'class': 'pool', 'from': 'conv1', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv_merged': {'axes': 'static', 'class': 'merge_dims', 'from': 'conv1p'},
  'decision': {'class': 'decide', 'from': 'output', 'loss': 'edit_distance', 'target': 'bpe'},
  'enc_ctx': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'encoder', 'n_out': 1024, 'with_bias': True},
  'enc_value': {'axis': 'F', 'class': 'split_dims', 'dims': (1, 2048), 'from': 'encoder'},
  'encoder': {'class': 'copy', 'from': ['lstm5_fw', 'lstm5_bw']},
  'inv_fertility': {'activation': 'sigmoid', 'class': 'linear', 'from': 'encoder', 'n_out': 1, 'with_bias': False},
  'lstm0_bw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'conv_merged',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm0_fw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'conv_merged',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm0_pool': {'class': 'pool', 'from': ['lstm0_fw', 'lstm0_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (3,), 'trainable': False},
  'lstm1_bw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm0_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm1_fw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm0_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm1_pool': {'class': 'pool', 'from': ['lstm1_fw', 'lstm1_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (2,), 'trainable': False},
  'lstm2_bw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm1_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm2_fw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm1_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm2_pool': {'class': 'pool', 'from': ['lstm2_fw', 'lstm2_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm3_bw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm2_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm3_fw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm2_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm3_pool': {'class': 'pool', 'from': ['lstm3_fw', 'lstm3_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm4_bw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm3_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm4_fw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm3_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm4_pool': {'class': 'pool', 'from': ['lstm4_fw', 'lstm4_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm5_bw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm4_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'lstm5_fw': { 'L2': 0.0001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm4_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.1}},
  'output': { 'class': 'rec',
              'from': [],
              'max_seq_len': "max_len_from('base:encoder')",
              'target': 'bpe',
              'unit': { 'accum_att_weights': { 'class': 'eval',
                                               'eval': 'source(0) + source(1) * source(2) * 0.5',
                                               'from': ['prev:accum_att_weights', 'att_weights', 'base:inv_fertility'],
                                               'out_type': {'dim': 1, 'shape': (None, 1)}},
                        'am_scale': { 'add_batch_axis': False,
                                      'class': 'variable',
                                      'init': 'random_normal_initializer(mean=1.0, stddev=0.5)',
                                      'shape': [534],
                                      'trainable': True},
                        'att': {'axes': 'except_batch', 'class': 'merge_dims', 'from': 'att0'},
                        'att0': {'base': 'base:enc_value', 'class': 'generic_attention', 'weights': 'att_weights'},
                        'att_weights': {'class': 'dropout', 'dropout': 0.1, 'dropout_noise_shape': {'*': None}, 'from': 'att_weights0'},
                        'att_weights0': {'class': 'softmax_over_spatial', 'from': 'energy'},
                        'combo_output_log_prob': { 'class': 'eval',
                                                   'eval': 'source(2) * safe_log(source(0)) + source(3) * safe_log(source(1)) - '
                                                           'tf.math.reduce_logsumexp(source(2) * safe_log(source(0)) + source(3) * '
                                                           'safe_log(source(1)), axis=-1, keepdims=True)',
                                                   'from': ['output_prob', 'lm_output', 'am_scale', 'lm_scale']},
                        'combo_output_prob': { 'class': 'eval',
                                               'eval': 'tf.exp(source(0))',
                                               'from': ['combo_output_log_prob'],
                                               'loss': 'ce',
                                               'target': 'bpe'},
                        'end': {'class': 'compare', 'from': 'output', 'kind': 'equal', 'value': 0},
                        'energy': {'activation': None, 'class': 'linear', 'from': 'energy_tanh', 'n_out': 1, 'with_bias': False},
                        'energy_in': {'class': 'combine', 'from': ['base:enc_ctx', 'weight_feedback', 's_transformed'], 'kind': 'add', 'n_out': 1024},
                        'energy_tanh': {'activation': 'tanh', 'class': 'activation', 'from': 'energy_in'},
                        'lm_dec_0': {'class': 'copy', 'from': 'lm_dec_0_ff_out'},
                        'lm_dec_0_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_0_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_0_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_0_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_0_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_0_ff_conv2'},
                        'lm_dec_0_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_0_self_att_out'},
                        'lm_dec_0_ff_out': {'class': 'combine', 'from': ['lm_dec_0_ff_drop', 'lm_dec_0_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_0_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_0_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_0_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_0_self_att_lin'},
                        'lm_dec_0_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_target_embed_lin'},
                        'lm_dec_0_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_0_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_0_self_att_out': { 'class': 'combine',
                                                   'from': ['lm_dec_0_self_att_drop', 'lm_target_embed_lin'],
                                                   'kind': 'add',
                                                   'n_out': 1024},
                        'lm_dec_1': {'class': 'copy', 'from': 'lm_dec_1_ff_out'},
                        'lm_dec_1_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_1_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_1_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_1_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_1_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_1_ff_conv2'},
                        'lm_dec_1_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_1_self_att_out'},
                        'lm_dec_1_ff_out': {'class': 'combine', 'from': ['lm_dec_1_ff_drop', 'lm_dec_1_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_1_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_1_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_1_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_1_self_att_lin'},
                        'lm_dec_1_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_0'},
                        'lm_dec_1_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_1_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_1_self_att_out': {'class': 'combine', 'from': ['lm_dec_1_self_att_drop', 'lm_dec_0'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_2': {'class': 'copy', 'from': 'lm_dec_2_ff_out'},
                        'lm_dec_2_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_2_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_2_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_2_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_2_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_2_ff_conv2'},
                        'lm_dec_2_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_2_self_att_out'},
                        'lm_dec_2_ff_out': {'class': 'combine', 'from': ['lm_dec_2_ff_drop', 'lm_dec_2_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_2_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_2_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_2_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_2_self_att_lin'},
                        'lm_dec_2_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_1'},
                        'lm_dec_2_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_2_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_2_self_att_out': {'class': 'combine', 'from': ['lm_dec_2_self_att_drop', 'lm_dec_1'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_3': {'class': 'copy', 'from': 'lm_dec_3_ff_out'},
                        'lm_dec_3_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_3_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_3_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_3_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_3_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_3_ff_conv2'},
                        'lm_dec_3_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_3_self_att_out'},
                        'lm_dec_3_ff_out': {'class': 'combine', 'from': ['lm_dec_3_ff_drop', 'lm_dec_3_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_3_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_3_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_3_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_3_self_att_lin'},
                        'lm_dec_3_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_2'},
                        'lm_dec_3_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_3_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_3_self_att_out': {'class': 'combine', 'from': ['lm_dec_3_self_att_drop', 'lm_dec_2'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_4': {'class': 'copy', 'from': 'lm_dec_4_ff_out'},
                        'lm_dec_4_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_4_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_4_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_4_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_4_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_4_ff_conv2'},
                        'lm_dec_4_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_4_self_att_out'},
                        'lm_dec_4_ff_out': {'class': 'combine', 'from': ['lm_dec_4_ff_drop', 'lm_dec_4_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_4_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_4_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_4_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_4_self_att_lin'},
                        'lm_dec_4_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_3'},
                        'lm_dec_4_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_4_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_4_self_att_out': {'class': 'combine', 'from': ['lm_dec_4_self_att_drop', 'lm_dec_3'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_5': {'class': 'copy', 'from': 'lm_dec_5_ff_out'},
                        'lm_dec_5_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_5_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_5_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_5_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_5_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_5_ff_conv2'},
                        'lm_dec_5_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_5_self_att_out'},
                        'lm_dec_5_ff_out': {'class': 'combine', 'from': ['lm_dec_5_ff_drop', 'lm_dec_5_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_5_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_5_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_5_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_5_self_att_lin'},
                        'lm_dec_5_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_4'},
                        'lm_dec_5_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_5_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_5_self_att_out': {'class': 'combine', 'from': ['lm_dec_5_self_att_drop', 'lm_dec_4'], 'kind': 'add', 'n_out': 1024},
                        'lm_decoder': {'class': 'layer_norm', 'from': 'lm_dec_5'},
                        'lm_output': { 'class': 'softmax',
                                       'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', scale=1.0)",
                                       'from': 'lm_decoder',
                                       'loss': None,
                                       'target': 'bpe',
                                       'with_bias': True},
                        'lm_scale': { 'add_batch_axis': False,
                                      'class': 'variable',
                                      'init': 'random_normal_initializer(mean=1.0, stddev=0.5)',
                                      'shape': [534],
                                      'trainable': True},
                        'lm_target_embed': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_target_embed_with_pos'},
                        'lm_target_embed_lin': { 'activation': None,
                                                 'class': 'linear',
                                                 'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                         'scale=1.0)',
                                                 'from': 'lm_target_embed',
                                                 'n_out': 1024,
                                                 'with_bias': False},
                        'lm_target_embed_raw': { 'activation': None,
                                                 'class': 'linear',
                                                 'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                         'scale=1.0)',
                                                 'from': 'prev:output',
                                                 'n_out': 128,
                                                 'param_device': 'CPU',
                                                 'with_bias': False},
                        'lm_target_embed_with_pos': {'add_to_input': True, 'class': 'positional_encoding', 'from': 'lm_target_embed_raw'},
                        'output': {'beam_size': 12, 'class': 'choice', 'from': 'output_prob', 'initial_output': 0, 'target': 'bpe'},
                        'output_prob': {'L2': 0.0001, 'class': 'softmax', 'dropout': 0.3, 'from': 'readout', 'loss': None, 'target': 'bpe'},
                        'readout': {'class': 'reduce_out', 'from': 'readout_in', 'mode': 'max', 'num_pieces': 2},
                        'readout_in': { 'activation': None,
                                        'class': 'linear',
                                        'from': ['s', 'prev:target_embed', 'att'],
                                        'n_out': 1000,
                                        'with_bias': True},
                        's': { 'class': 'rnn_cell',
                               'from': ['prev:target_embed', 'prev:att'],
                               'n_out': 1000,
                               'unit': 'zoneoutlstm',
                               'unit_opts': {'zoneout_factor_cell': 0.15, 'zoneout_factor_output': 0.05}},
                        's_transformed': {'activation': None, 'class': 'linear', 'from': 's', 'n_out': 1024, 'with_bias': False},
                        'target_embed': { 'activation': None,
                                          'class': 'linear',
                                          'from': 'output',
                                          'initial_output': 0,
                                          'n_out': 621,
                                          'with_bias': False},
                        'weight_feedback': { 'activation': None,
                                             'class': 'linear',
                                             'from': 'prev:accum_att_weights',
                                             'n_out': 1024,
                                             'with_bias': False}}},
  'source0': {'axis': 'F', 'class': 'split_dims', 'dims': (-1, 1), 'from': 'data'}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 6
newbob_multi_update_interval = 1
num_epochs = 100
optimizer_epsilon = 1e-08
preload_from_files = { 'lm_model': { 'filename': '/work/asr4/zeineldeen/setups-data/switchboard/2021-02-21--lm-bpe/work/crnn/training/CRNNTrainingFromFile.MmcRaR7Mfdob/output/models/epoch.019',
                'ignore_missing': True,
                'init_for_train': True,
                'prefix': 'lm_'},
  'load_model': { 'filename': '/u/zeineldeen/setups/switchboard/2021-04-17--long-train/work/crnn/training/CRNNTrainingJob.5mxqvnz6Xnx6/output/models/epoch.198',
                  'ignore_missing': True,
                  'init_for_train': True}}
pretrain = None
save_interval = 1
search_output_layer = 'decision'
target = 'bpe'
task = 'train'
tf_log_memory_usage = True
train = { 'bpe': { 'bpe_file': '/u/zeineldeen/setups/switchboard/2021-04-17--long-train/work/bpe/train/ReturnnTrainBpeJob.oCWOav11gY6s/output/bpe.codes',
           'seq_postfix': [0],
           'unknown_label': None,
           'vocab_file': '/u/zeineldeen/setups/switchboard/2021-04-17--long-train/work/bpe/train/ReturnnTrainBpeJob.oCWOav11gY6s/output/bpe.vocab'},
  'class': 'ExternSprintDataset',
  'estimated_num_seqs': 37841,
  'input_stddev': 3.0,
  'partitionEpoch': 6,
  'sprintConfigStr': [ '--config=/u/zeineldeen/setups/switchboard/2020-07-16--phon-att-sis/dependencies/rasr_configs/training.config',
                       '--*.corpus.file=`cf /work/asr3/irie/data/switchboard/corpora/train.corpus.gz`',
                       '--*.corpus.segments.file=`cf /u/tuske/work/ASR/switchboard/corpus/train.segments`',
                       '--*.corpus.segment-order-shuffle=true',
                       '--*.segment-order-sort-by-time-length=true',
                       '--*.segment-order-sort-by-time-length-chunk-size=6000',
                       '--*.feature-cache-path=`cf /u/tuske/work/ASR/switchboard/feature.extraction/gt40_40/data/gt.train.bundle`',
                       '--*.log-channel.file=train.sprint.log',
                       '--*.window-size=1'],
  'sprintTrainerExecPath': '/u/zhou/rasr-dev/arch/linux-x86_64-standard/nn-trainer.linux-x86_64-standard'}
truncation = -1
update_on_device = True
use_learning_rate_control_always = True
use_tensorflow = True
window = 1
config = {}

locals().update(**config)



def _fix_layer(layer_dict):
  if layer_dict["class"] == "rec":
      unit = layer_dict["unit"]
      if isinstance(unit, dict):
          _fix_net(unit)
          return
  layer_dict["trainable"] = False
  if "dropout" in layer_dict:
      layer_dict["dropout"] = 0


def _fix_net(net_dict):
    for key, value in net_dict.items():
        if key.endswith('_scale'):
          continue
        _fix_layer(value)

_fix_net(network)

