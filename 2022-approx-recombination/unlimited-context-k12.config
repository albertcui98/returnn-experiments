#!rnn.py


def custom_score_combine(layer, scores_in, scores_base, batch_dim, scores_beam_in, base_beam_in, t, end_flags, **kwargs):
    """
    :param ChoiceLayer layer:                                   `ChoiceLayer` from which to fetch the `histories`
    :param tf.Tensor scores_in: (batch, base_beam_in, dim)      the scores for each target word given the sequences in the beams so far (note: `dim` = `n_classes`)
    :param tf.Tensor scores_base: (batch, base_beam_in, dim|1)  the score of each sequences within each beam within the batch until the current decoding step
    :param tf.Tensor batch_dim: ()                              indicates the batch dimension size `batch`
    :param tf.Tensor scores_beam_in: ()                         NPW: looks similar to base_beam_in to me, I don't know what it does
    :param tf.Tensor base_beam_in: ()                           indicates the width of the base beam (initially 1 then beam_size)
    :param tf.Tensor t: ()                                      indicates the time step beginning at 0
    :param tf.Tensor end_flags: (batch, base_beam_in)           indicates which sequences within the beam already terminated by setting the respective entry to 1
    :return: (batch, base_beam_in, dim)                         scores_base combined with scores_in according to the BSR algorithm
    :rtype: tf.Tensor
    """
    import tensorflow as tf

    ##################################################################################################
    #   Pre-process input
    ##################################################################################################

    cheating = layer.cheating
    assert cheating in ["exclusive", False], "Unsupported value for ChoiceLayer.cheating: '{}'".format(str(cheating))

    histories = layer.explicit_search_sources[0].output.copy_as_batch_major().placeholder  # (batch, beam, history)

    if False:
        histories = tf.Print(histories, [scores_in, tf.shape(scores_in), t], message="\n=== Next Step ===\n[BSR:INPUT] scores_in and its shape: ", summarize=-1)
        histories = tf.Print(histories, [scores_base, tf.shape(scores_base), t], message="[BSR:INPUT] scores_base and its shape: ", summarize=-1)
        histories = tf.Print(histories, [batch_dim, tf.shape(batch_dim), t], message="[BSR:INPUT] batch_dim and its shape: ", summarize=-1)
        histories = tf.Print(histories, [scores_beam_in, tf.shape(scores_beam_in), t], message="[BSR:INPUT] scores_beam_in and its shape: ", summarize=-1)
        histories = tf.Print(histories, [base_beam_in, tf.shape(base_beam_in), t], message="[BSR:INPUT] base_beam_in and its shape: ", summarize=-1)
        histories = tf.Print(histories, [t, tf.shape(t), t], message="[BSR:INPUT] t and its shape: ", summarize=-1)
        histories = tf.Print(histories, [end_flags, tf.shape(end_flags), t], message="[BSR:INPUT] end_flags and its shape: ", summarize=-1)
        histories = tf.Print(histories, [histories, tf.shape(histories), t], message="[BSR:INPUT] histories and its shape: ", summarize=-1)

    # Ensure that the histories are of shape (batch_dim, beam_size, history_length). Note if batch_dim is 1, then the batch dimension
    # dimension is omitted, hence the insurance here.
    # Note that in the first search step, there are `beam_size` histories for each batch entry. However, there is only 1 scores_base entry
    # for each batch entry. Note in this step applies `base_beam_in` = 1 != `beam_size`, so there is a mismatch in the beam dimension assumed
    # by scores_base and the histories, which are fetched from the window layer.
    # Since, in this step, the histories all contain 0 anyway, we crop the histories by simply selecting the first history for each batch entry.
    histories = tf.reshape(histories, shape=[batch_dim, scores_beam_in, tf.shape(histories)[-1]])
    histories = histories[:, 0:base_beam_in]

    scores_base = tf.squeeze(scores_base, axis=-1)  # (batch,beam,)
    scores_base_flat = tf.reshape(scores_base, [-1])  # (batch*beam,)

    if False:
        histories = tf.Print(histories, [histories, tf.shape(histories), t], message="[BSR:PREPARE] histories and its shape: ", summarize=-1)

    ##################################################################################################
    #   Determine history matches
    ##################################################################################################

    # create a confusion matrix indicating the equality between the histories within a beam
    h1 = tf.expand_dims(histories, axis=1)  # (batch, beam, 1, history)
    h2 = tf.expand_dims(histories, axis=2)  # (batch, 1, beam, history)
    confusion_matrix_word_matches = tf.equal(h1, h2)  # (batch, beam, beam, history)
    confusion_matrix_sequence_matches = tf.reduce_all(confusion_matrix_word_matches, axis=-1)  # (batch, beam, beam)

    # fetch the index tuples (batch, beam_i, beam_j) for the entries of the confusion matrix, which
    # indicate history matches.
    # the output are these tuples (batch, beam_i, beam_j) where beam_i and beam_j have the same predecessor words
    tmp_indices = tf.cast(tf.where(confusion_matrix_sequence_matches), dtype=tf.int32)  # (?,3)

    # This gives us for all recent histories within the batch, the index of the first matching
    # recent history within its respective beam, regardless of if this is the recent history itself, or
    # a recent history from a different sequence, appearing earlier in the sequence order.
    # Note that we expect the recent histories to be ordered by their sequence's score, meaning that
    # we automatically get the index of the matching recent history of the sequence with the highest
    # sequence score.
    segment_data = tmp_indices[:, -1]
    segment_ids = base_beam_in * tmp_indices[:, 0] + tmp_indices[:, 1]
    match_indices = tf.segment_min(segment_data, segment_ids)
    match_indices.set_shape(scores_base_flat.shape)  # (batch*beam,)  We know this by construction.

    ##################################################################################################
    #   if merge eos instantly
    ##################################################################################################

    if True:
        # If `True` is set, we want to merge terminated sequences immediately, disregarding
        # their BSR histories. If it is not set, terminated sequences would be merged only if they share the
        # same BSR history, which becomes (mainly) the case when the history window covers just the padding
        # eos-tokens of those sequences.

        # Create a mask to "excluded" non-eos positions from the subsequent reduce_min operation
        # We simply set all excluded entries to a sufficiently high value
        not_end_flags = tf.ones_like(end_flags, dtype=tf.int32) - tf.cast(end_flags, tf.int32)
        not_end_mask = not_end_flags * (tf.shape(match_indices)[0] + 1)
        # Determine the beam index into which to merge all terminated sequences within a beam
        eos_matches = tf.reshape(tf.range(tf.shape(match_indices)[0]) % base_beam_in, shape=tf.shape(end_flags)) * tf.cast(end_flags, tf.int32) + not_end_mask
        eos_matches = tf.reduce_min(eos_matches, axis=-1, keep_dims=True)
        # Alter the match_indices such that the terminated sequences are merged into the correct entry
        eos_mask = tf.cast(end_flags, tf.int32) * eos_matches
        match_indices = match_indices * tf.reshape(not_end_flags, shape=tf.shape(match_indices)) + tf.reshape(eos_mask, shape=tf.shape(match_indices))

    ##################################################################################################
    #   if reference in beam
    ##################################################################################################

    if cheating == "exclusive":
        # If cheating is 'exclusive', the reference target sequence will be always in the last entry of the respective beam.
        # If the reference is about to get recombined with one or more sequences within the beam, we want to ensure that those
        # sequences are merged into the reference regardless of whether it has the highest score under these sequences.

        # Fetch the indices of the beam entries into which die reference are about to get merged
        reference_merge_target = tf.expand_dims(match_indices[base_beam_in - 1::base_beam_in], -1)  # (batch,1)
        # Now search the beams for other sequences, which are about to get merged into these entries
        reference_merge_siblings = tf.reshape(match_indices, shape=tf.shape(scores_base))  # (batch,beam)
        reference_merge_siblings = tf.cast(tf.equal(reference_merge_siblings, reference_merge_target), dtype=tf.int32)  # (batch,beam)
        reference_merge_siblings = tf.reshape(reference_merge_siblings, shape=tf.shape(match_indices))  # (batch*beam,)
        not_reference_merge_siblings = tf.ones_like(reference_merge_siblings, dtype=tf.int32) - reference_merge_siblings

        # Redirect all affected sequences to the reference position
        match_indices = match_indices * not_reference_merge_siblings
        match_indices = match_indices + reference_merge_siblings * (base_beam_in - 1)

    ##################################################################################################
    #   Filter padded sequences and terminated searches
    ##################################################################################################

    # Create masks, indicating which sequences are allowed to be recombined and which aren't (or the opposite), according to the rules described at `is_padded` and `is_search_terminated`
    # Note: we don't use logical 'or' (= '+'), because we want to have values being 0 or 1, and 1 + 1 = 2.
    merge_allow_mask = tf.ones_like(scores_base, dtype=tf.int32)

    # If False or True, we don't apply the subsequent mask...
    if not False and not True:
        # Check for each sequence in the beam, whether it is padded (has more than 1 tailing </s>)
        # For sequences with a tailing </s> we only want to recombine those, which just terminated,
        # not those which were already padded with extra </s> tokens.
        is_padded = tf.cast(tf.equal(tf.reduce_sum(histories[:, :, -2:], axis=-1), 0), tf.int32)
        is_not_padded = tf.ones_like(is_padded) - is_padded
        merge_allow_mask = merge_allow_mask * is_not_padded

    # Check for each beam in the batch, whether the search is already terminated (all end_flags = 1)
    # In case the search is already terminated, we don't want to recombine sequences no matter
    # which histories they have, because there would be no sequence to take their place in the beam.
    is_search_terminated = tf.reduce_prod(tf.cast(end_flags, tf.int32), axis=-1)
    is_not_search_terminated = tf.expand_dims(tf.ones_like(is_search_terminated, dtype=tf.int32) - is_search_terminated, axis=-1)
    merge_allow_mask = merge_allow_mask * is_not_search_terminated

    # finalize the merge masks
    merge_allow_mask = tf.reshape(merge_allow_mask, tf.shape(match_indices))
    merge_forbid_mask = tf.ones_like(merge_allow_mask) - merge_allow_mask

    # Using these masks, (re-)direct those sequences, which are not allowed to be merged into another sequence, to their original index
    match_indices = match_indices * merge_allow_mask
    match_indices = match_indices + (tf.range(tf.shape(match_indices)[0]) % base_beam_in) * merge_forbid_mask

    ##################################################################################################
    #   Determine recombinations
    ##################################################################################################

    # Next, construct a list of scatter indices, containing for each sequence within the batch tensor:
    # * the batch index `batch_idx`, indicating the index of the originating input sequence within the batch
    # * the match index `match_idx`, indicating the index of the first sequence with a matching history, respective to the beam
    # * the stack index `stack_idx`, indicating the originating index of the sequence, respective to its beam
    batch_idx = tf.range(tf.shape(match_indices)[0]) // base_beam_in  # (batch*beam,)
    match_idx = match_indices  # (batch*beam,)
    stack_idx = tf.range(tf.shape(match_indices)[0]) % base_beam_in  # (batch*beam,)
    # E.g. the columns result in the the scatter indices:
    # [0 0 0 0  1 1 1 1  2 2 2 2] = batch_idx
    # [0 1 0 3  0 1 1 3  0 1 2 2] = match_idx
    # [0 1 2 3  0 1 2 3  0 1 2 3] = stack_idx
    scatter_indices = tf.stack([batch_idx, match_idx, stack_idx], axis=-1)  # (batch*beam, 2)

    if False:
        scatter_indices = tf.Print(scatter_indices, [batch_idx, tf.shape(batch_idx), t], message="[BSR:SCATTER] batch_idx and its shape: ", summarize=-1)
        scatter_indices = tf.Print(scatter_indices, [match_idx, tf.shape(match_idx), t], message="[BSR:SCATTER] match_idx and its shape: ", summarize=-1)
        scatter_indices = tf.Print(scatter_indices, [stack_idx, tf.shape(stack_idx), t], message="[BSR:SCATTER] stack_idx and its shape: ", summarize=-1)
        scatter_indices = tf.Print(scatter_indices, [scatter_indices, tf.shape(scatter_indices), t], message="[BSR:SCATTER] scatter_indices and its shape: ", summarize=-1)

    ##################################################################################################
    #   Perform recombinations and compute scores
    ##################################################################################################

    # We want to combine our scores_base, which are (pseudo) log-probs, by summing them in probability space.
    # To compute this efficiently, we make use of the LogSumExp trick:

    # To apply LogSumExp, we use the scatter_indices and scatter_nd, to create a scatter_stack matrix, containing the scores which are meant to be
    # combined with LogSumExp under its last dimension. However, those matrices will have entries, which were initialized with 0, and which should
    # be excluded by LogSumExp. To exclude them, we mask out those entries by setting them to -inf (= log(0)), hence LogSumExp will treat those
    # entries as 0 in its internal sum. The following tensors are used to create that -inf mask:
    scatter_track = tf.scatter_nd(scatter_indices, tf.ones_like(scores_base_flat, dtype=tf.int32), tf.shape(confusion_matrix_sequence_matches))  # (batch, beam, beam)
    neg_inf_tensor = float('-inf') * tf.ones_like(scatter_track, dtype=tf.float32)  # (batch, beam, beam)
    neg_inf_mask = tf.equal(scatter_track, 0)  # (batch, beam, beam)

    # create the scatter_stack tensor by scattering the scores_base to its designated positions and apply the -inf mask to unused entries:
    scatter_stack = tf.scatter_nd(scatter_indices, scores_base_flat, tf.shape(confusion_matrix_sequence_matches))  # (batch, beam, beam)
    scatter_stack = tf.where(neg_inf_mask, neg_inf_tensor, scatter_stack)

    # now combine the scores by applying LogSumExp:
    new_scores_base = tf.reduce_logsumexp(scatter_stack, axis=-1, keep_dims=True)  # (batch, beam, dim|1)

    scores_out = new_scores_base + scores_in

    if False:
        scores_out = tf.Print(scores_out, [new_scores_base, tf.shape(new_scores_base), t], message="[BSR:COMPUTE] new_scores_base and its shape: ", summarize=-1)
        scores_out = tf.Print(scores_out, [scores_out, tf.shape(scores_out), t], message="[BSR:OUTPUT] scores_out and its shape: ", summarize=-1)

    return scores_out



accum_grad_multiple_step = 10
adam = True
batch_size = 10000
batching = 'random'
cache_size = '0'
cleanup_old_models = {'keep': [20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260, 280, 300, 320, 340]}
debug_print_layer_output_template = True
dev = {   'audio': {   'norm_mean': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/stats.mean.txt',
                 'norm_std_dev': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/stats.std_dev.txt'},
    'bpe': {   'bpe_file': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/trans.bpe.codes',
               'seq_postfix': [0],
               'unknown_label': '<unk>',
               'vocab_file': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/trans.bpe.vocab'},
    'class': 'LibriSpeechCorpus',
    'fixed_random_seed': 1,
    'fixed_random_subset': 3000,
    'path': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/ogg-zips',
    'prefix': 'dev',
    'seq_ordering': 'sorted_reverse',
    'use_cache_manager': True,
    'use_ogg': True,
    'use_zip': True}
device = 'gpu'
gradient_clip = 0
gradient_noise = 0.0
learning_rate = 1e-05
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
learning_rate_file = 'learning_rates'
log = ['./crnn.log']
log_batch_size = True
log_verbosity = 3
max_seq_length = {'classes': 75}
max_seqs = 1
min_learning_rate = 1e-06
model = '/u/wynands/workspace/repository/experiments/asr-mmi/work/crnn/training/CRNNTrainingJob.khSq8ZNzf8Jr/output/models/epoch'
multiprocessing = True
network = {   'conv0': {   'L2': 0.0001,
                 'activation': None,
                 'class': 'conv',
                 'filter_size': (3, 3),
                 'from': 'source0',
                 'n_out': 32,
                 'padding': 'same',
                 'with_bias': True},
    'conv0p': {'class': 'pool', 'from': 'conv0', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2)},
    'conv1': {   'L2': 0.0001,
                 'activation': None,
                 'class': 'conv',
                 'filter_size': (3, 3),
                 'from': 'conv0p',
                 'n_out': 32,
                 'padding': 'same',
                 'with_bias': True},
    'conv1p': {'class': 'pool', 'from': 'conv1', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2)},
    'conv_merged': {'axes': 'static', 'class': 'merge_dims', 'from': 'conv1p'},
    'ctc': {   'class': 'softmax',
               'from': ['encoder'],
               'loss': 'ctc',
               'loss_opts': {'beam_width': 1, 'ctc_opts': {'ignore_longer_outputs_than_inputs': True}},
               'target': 'classes'},
    'decision': {'class': 'decide', 'from': ['output'], 'loss': 'edit_distance', 'loss_opts': {}, 'target': 'classes'},
    'denominator_score': {   'class': 'eval',
                             'eval': 'tf.math.reduce_logsumexp(source(0, auto_convert=False), axis=1, keepdims=False)',
                             'from': ['split_scores'],
                             'loss': 'as_is',
                             'loss_opts': {'scale': 1.0},
                             'out_type': {'batch_dim_axis': 0, 'dim': None, 'dtype': 'float32', 'shape': (), 'sparse': False, 'time_dim_axis': None}},
    'enc_ctx': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': ['encoder'], 'n_out': 1024, 'with_bias': True},
    'enc_value': {'axis': 'F', 'class': 'split_dims', 'dims': (1, 2048), 'from': ['encoder']},
    'encoder': {'class': 'copy', 'from': ['lstm5_fw', 'lstm5_bw']},
    'extra.search:output': {   'cheating': 'exclusive',
                               'class': 'rec',
                               'from': [],
                               'max_seq_len': "max_len_from('base:encoder')",
                               'target': 'classes',
                               'unit': {   'accum_att_weights': {   'class': 'eval',
                                                                    'eval': 'source(0) + source(1) * source(2) * 0.5',
                                                                    'from': ['prev:accum_att_weights', 'att_weights', 'base:inv_fertility'],
                                                                    'out_type': {'dim': 1, 'shape': (None, 1)}},
                                           'att': {'axes': 'except_batch', 'class': 'merge_dims', 'from': ['att0']},
                                           'att0': {'base': 'base:enc_value', 'class': 'generic_attention', 'weights': 'att_weights'},
                                           'att_weights': {'class': 'softmax_over_spatial', 'from': ['energy']},
                                           'combo_output_log_prob': {   'class': 'eval',
                                                                        'eval': 'am_scale * safe_log(source(0)) + lm_scale * safe_log(source(1))',
                                                                        'eval_locals': {'am_scale': 0.3, 'lm_scale': 0.1},
                                                                        'from': ['output_prob', 'lm_output_prob']},
                                           'combo_output_prob': {   'class': 'eval',
                                                                    'eval': 'tf.exp(source(0))',
                                                                    'from': ['combo_output_log_prob'],
                                                                    'target': 'classes'},
                                           'end': {'class': 'compare', 'from': ['output'], 'value': 0},
                                           'energy': {'activation': None, 'class': 'linear', 'from': ['energy_tanh'], 'n_out': 1, 'with_bias': False},
                                           'energy_in': {   'class': 'combine',
                                                            'from': ['base:enc_ctx', 'weight_feedback', 's_transformed'],
                                                            'kind': 'add',
                                                            'n_out': 1024},
                                           'energy_tanh': {'activation': 'tanh', 'class': 'activation', 'from': ['energy_in']},
                                           'lm_output': {   'class': 'subnetwork',
                                                            'from': ['prev:output'],
                                                            'load_on_init': '/work/asr4/michel/setups-data/language_modelling/librispeech/neurallm/decoder_sized_transcripts_only/net-model/network.007',
                                                            'n_out': 10025,
                                                            'subnetwork': {   'input': {   'activation': 'identity',
                                                                                           'class': 'linear',
                                                                                           'n_out': 128,
                                                                                           'trainable': False},
                                                                              'lstm0': {   'class': 'rnn_cell',
                                                                                           'from': ['input'],
                                                                                           'n_out': 1000,
                                                                                           'trainable': False,
                                                                                           'unit': 'LSTMBlock',
                                                                                           'unit_opts': {'forget_bias': 0.0}},
                                                                              'output': {   'activation': 'identity',
                                                                                            'class': 'linear',
                                                                                            'from': ['lstm0'],
                                                                                            'n_out': 10025,
                                                                                            'trainable': False,
                                                                                            'use_transposed_weights': False}},
                                                            'trainable': False},
                                           'lm_output_prob': {'activation': 'softmax', 'class': 'activation', 'from': ['lm_output']},
                                           'output': {   'beam_size': 8,
                                                         'cheating': 'exclusive',
                                                         'class': 'choice',
                                                         'custom_score_combine': custom_score_combine,
                                                         'explicit_search_sources': ['output_history'],
                                                         'from': ['combo_output_log_prob'],
                                                         'initial_output': 0,
                                                         'input_type': 'log_prob',
                                                         'is_output_layer': True,
                                                         'length_normalization': False,
                                                         'target': 'classes'},
                                           'output_history': {'class': 'window', 'from': ['prev:output'], 'window_left': 12, 'window_size': 12},
                                           'output_prob': {   'L2': 0.0001,
                                                              'class': 'softmax',
                                                              'dropout': 0.3,
                                                              'from': ['readout'],
                                                              'target': 'classes'},
                                           'readout': {'class': 'reduce_out', 'from': ['readout_in'], 'mode': 'max', 'num_pieces': 2},
                                           'readout_in': {   'activation': None,
                                                             'class': 'linear',
                                                             'from': ['s', 'prev:target_embed', 'att'],
                                                             'n_out': 1000},
                                           's': {   'L2': 0.0001,
                                                    'class': 'rec',
                                                    'from': ['prev:target_embed', 'prev:att'],
                                                    'n_out': 1000,
                                                    'unit': 'nativelstm2'},
                                           's_transformed': {'activation': None, 'class': 'linear', 'from': ['s'], 'n_out': 1024, 'with_bias': False},
                                           'target_embed': {   'activation': None,
                                                               'class': 'linear',
                                                               'from': ['output'],
                                                               'initial_output': 0,
                                                               'n_out': 621,
                                                               'with_bias': False},
                                           'weight_feedback': {   'activation': None,
                                                                  'class': 'linear',
                                                                  'from': ['prev:accum_att_weights'],
                                                                  'n_out': 1024,
                                                                  'with_bias': False}}},
    'get_scores': {'class': 'choice_get_beam_scores', 'from': ['extra.search:output']},
    'inv_fertility': {'activation': 'sigmoid', 'class': 'linear', 'from': ['encoder'], 'n_out': 1, 'with_bias': False},
    'lstm0_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': ['conv_merged'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm0_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': ['conv_merged'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm0_pool': {'class': 'pool', 'from': ['lstm0_fw', 'lstm0_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (3,), 'trainable': False},
    'lstm1_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': ['lstm0_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm1_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': ['lstm0_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm1_pool': {'class': 'pool', 'from': ['lstm1_fw', 'lstm1_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (2,), 'trainable': False},
    'lstm2_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': ['lstm1_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm2_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': ['lstm1_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm2_pool': {'class': 'pool', 'from': ['lstm2_fw', 'lstm2_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
    'lstm3_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': ['lstm2_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm3_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': ['lstm2_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm3_pool': {'class': 'pool', 'from': ['lstm3_fw', 'lstm3_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
    'lstm4_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': ['lstm3_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm4_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': ['lstm3_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm4_pool': {'class': 'pool', 'from': ['lstm4_fw', 'lstm4_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
    'lstm5_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': ['lstm4_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'lstm5_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': ['lstm4_pool'], 'n_out': 1024, 'unit': 'nativelstm2'},
    'output': {   'cheating': False,
                  'class': 'rec',
                  'from': [],
                  'max_seq_len': "max_len_from('base:encoder')",
                  'target': 'classes',
                  'unit': {   'accum_att_weights': {   'class': 'eval',
                                                       'eval': 'source(0) + source(1) * source(2) * 0.5',
                                                       'from': ['prev:accum_att_weights', 'att_weights', 'base:inv_fertility'],
                                                       'out_type': {'dim': 1, 'shape': (None, 1)}},
                              'att': {'axes': 'except_batch', 'class': 'merge_dims', 'from': ['att0']},
                              'att0': {'base': 'base:enc_value', 'class': 'generic_attention', 'weights': 'att_weights'},
                              'att_weights': {'class': 'softmax_over_spatial', 'from': ['energy']},
                              'combo_output_log_prob': {   'class': 'eval',
                                                           'eval': 'am_scale * safe_log(source(0)) + lm_scale * safe_log(source(1))',
                                                           'eval_locals': {'am_scale': 0.3, 'lm_scale': 0.1},
                                                           'from': ['output_prob', 'lm_output_prob']},
                              'combo_output_prob': {   'class': 'eval',
                                                       'eval': 'tf.exp(source(0))',
                                                       'from': ['combo_output_log_prob'],
                                                       'loss': 'ce',
                                                       'loss_opts': {},
                                                       'target': 'classes'},
                              'end': {'class': 'compare', 'from': ['output'], 'value': 0},
                              'energy': {'activation': None, 'class': 'linear', 'from': ['energy_tanh'], 'n_out': 1, 'with_bias': False},
                              'energy_in': {   'class': 'combine',
                                               'from': ['base:enc_ctx', 'weight_feedback', 's_transformed'],
                                               'kind': 'add',
                                               'n_out': 1024},
                              'energy_tanh': {'activation': 'tanh', 'class': 'activation', 'from': ['energy_in']},
                              'lm_output': {   'class': 'subnetwork',
                                               'from': ['prev:output'],
                                               'load_on_init': '/work/asr4/michel/setups-data/language_modelling/librispeech/neurallm/decoder_sized_transcripts_only/net-model/network.007',
                                               'n_out': 10025,
                                               'subnetwork': {   'input': {   'activation': 'identity',
                                                                              'class': 'linear',
                                                                              'n_out': 128,
                                                                              'trainable': False},
                                                                 'lstm0': {   'class': 'rnn_cell',
                                                                              'from': ['input'],
                                                                              'n_out': 1000,
                                                                              'trainable': False,
                                                                              'unit': 'LSTMBlock',
                                                                              'unit_opts': {'forget_bias': 0.0}},
                                                                 'output': {   'activation': 'identity',
                                                                               'class': 'linear',
                                                                               'from': ['lstm0'],
                                                                               'n_out': 10025,
                                                                               'trainable': False,
                                                                               'use_transposed_weights': False}},
                                               'trainable': False},
                              'lm_output_prob': {'activation': 'softmax', 'class': 'activation', 'from': ['lm_output']},
                              'output': {   'beam_size': 12,
                                            'cheating': False,
                                            'class': 'choice',
                                            'from': ['combo_output_log_prob'],
                                            'initial_output': 0,
                                            'input_type': 'log_prob',
                                            'target': 'classes'},
                              'output_prob': {'L2': 0.0001, 'class': 'softmax', 'dropout': 0.3, 'from': ['readout'], 'target': 'classes'},
                              'readout': {'class': 'reduce_out', 'from': ['readout_in'], 'mode': 'max', 'num_pieces': 2},
                              'readout_in': {'activation': None, 'class': 'linear', 'from': ['s', 'prev:target_embed', 'att'], 'n_out': 1000},
                              's': {'L2': 0.0001, 'class': 'rec', 'from': ['prev:target_embed', 'prev:att'], 'n_out': 1000, 'unit': 'nativelstm2'},
                              's_transformed': {'activation': None, 'class': 'linear', 'from': ['s'], 'n_out': 1024, 'with_bias': False},
                              'target_embed': {   'activation': None,
                                                  'class': 'linear',
                                                  'from': ['output'],
                                                  'initial_output': 0,
                                                  'n_out': 621,
                                                  'with_bias': False},
                              'weight_feedback': {   'activation': None,
                                                     'class': 'linear',
                                                     'from': ['prev:accum_att_weights'],
                                                     'n_out': 1024,
                                                     'with_bias': False}}},
    'source': {'class': 'eval', 'eval': "self.network.get_config().typed_value('transform')(source(0), network=self.network)"},
    'source0': {'axis': 'F', 'class': 'split_dims', 'dims': (-1, 1), 'from': 'source'},
    'split_scores': {'axis': 'B', 'class': 'split_dims', 'dims': (-1, 8), 'from': ['get_scores']}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 20
newbob_multi_update_interval = 1
num_epochs = 360
num_inputs = 40
num_outputs = {'classes': (10025, 1), 'data': (40, 2)}
optimizer_epsilon = 1e-08
save_interval = 1
search_output_layer = 'decision'
target = 'classes'
task = 'train'
tf_log_memory_usage = True
train = {   'audio': {   'norm_mean': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/stats.mean.txt',
                 'norm_std_dev': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/stats.std_dev.txt'},
    'bpe': {   'bpe_file': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/trans.bpe.codes',
               'seq_postfix': [0],
               'unknown_label': '<unk>',
               'vocab_file': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/trans.bpe.vocab'},
    'class': 'LibriSpeechCorpus',
    'epoch_wise_filter': {   (1, 5): {'max_mean_len': 50, 'subdirs': ['train-clean-100', 'train-clean-360'], 'use_new_filter': True},
                             (5, 10): {'max_mean_len': 150, 'subdirs': ['train-clean-100', 'train-clean-360'], 'use_new_filter': True},
                             (11, 20): {'subdirs': ['train-clean-100', 'train-clean-360'], 'use_new_filter': True}},
    'partition_epoch': 20,
    'path': '/u/zeyer/setups/librispeech/2018-02-26--att/base/dataset/ogg-zips',
    'prefix': 'train',
    'seq_ordering': 'laplace:281',
    'use_cache_manager': True,
    'use_ogg': True,
    'use_zip': True}
truncation = -1
update_on_device = True
use_learning_rate_control_always = True
use_tensorflow = True
window = 1
config = {}

locals().update(**config)

def summary(name, x):
    """
    :param str name:
    :param tf.Tensor x: (batch,time,feature)
    """
    import tensorflow as tf
    # tf.summary.image wants [batch_size, height,  width, channels],
    # we have (batch, time, feature).
    img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
    img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
    tf.summary.image(name, img, max_outputs=10)
    tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
    mean = tf.reduce_mean(x)
    tf.summary.scalar("%s_mean" % name, mean)
    stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
    tf.summary.scalar("%s_stddev" % name, stddev)
    tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))

def mask(x, axis, pos, max_amount):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int axis:
    :param tf.Tensor pos: (batch,)
    :param int max_amount: inclusive
    """
    import tensorflow as tf
    ndim = x.get_shape().ndims
    n_batch = tf.shape(x)[0]
    dim = tf.shape(x)[axis]
    amount = tf.random_uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
    pos2 = tf.minimum(pos + amount, dim)
    idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
    pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
    pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
    cond = tf.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
    cond = tf.reshape(cond, [tf.shape(x)[i] if i in (0, axis) else 1 for i in range(ndim)])
    from TFUtil import where_bc
    x = where_bc(cond, 0.0, x)
    return x

def random_mask(x, axis, min_num, max_num, max_dims):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int axis:
    :param int|tf.Tensor min_num:
    :param int|tf.Tensor max_num: inclusive
    :param int max_dims: inclusive
    """
    import tensorflow as tf
    n_batch = tf.shape(x)[0]
    num = tf.random_uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
    # https://github.com/tensorflow/tensorflow/issues/9260
    # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
    z = -tf.log(-tf.log(tf.random_uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
    _, indices = tf.nn.top_k(z, tf.reduce_max(num))
    # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
    # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
    _, x = tf.while_loop(
        cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
        body=lambda i, x: (
            i + 1,
            tf.where(
                tf.less(i, num),
                mask(x, axis=axis, pos=indices[:, i], max_amount=max_dims),
                x)),
        loop_vars=(0, x))
    return x

def transform(x, network):
    import tensorflow as tf
    # summary("features", x)
    x = tf.clip_by_value(x, -3.0, 3.0)
    # summary("features_clip", x)

    def get_masked():
        x_masked = x
        x_masked = random_mask(x_masked, axis=1, min_num=1, max_num=tf.maximum(tf.shape(x)[1] // 100, 1), max_dims=20)
        x_masked = random_mask(x_masked, axis=2, min_num=1, max_num=2, max_dims=num_inputs // 5)
        # summary("features_mask", x_masked)
        return x_masked
    x = network.cond_on_train(get_masked, lambda: x)
    return x


def custom_construction_algo(idx, net_dict):
    # For debugging, use: python3 ./crnn/Pretrain.py config... Maybe set repetitions=1 below.
    StartNumLayers = 2
    InitialDimFactor = 0.5
    AttNumHeads = 1
    EncValuePerHeadDim = 2048
    orig_num_lstm_layers = 0
    while "lstm%i_fw" % orig_num_lstm_layers in net_dict:
        orig_num_lstm_layers += 1
    assert orig_num_lstm_layers >= 2
    orig_red_factor = 1
    for i in range(orig_num_lstm_layers - 1):
        orig_red_factor *= net_dict["lstm%i_pool" % i]["pool_size"][0]
    net_dict["#config"] = {}
    if idx < 4:
        net_dict["#config"]["batch_size"] = 15000
    idx = max(idx - 3, 0)  # repeat first
    num_lstm_layers = idx + StartNumLayers  # idx starts at 0. start with N layers
    if num_lstm_layers > orig_num_lstm_layers:
        # Finish. This will also use label-smoothing then.
        return None
    if num_lstm_layers == 2:
        net_dict["lstm0_pool"]["pool_size"] = (orig_red_factor,)
    # Skip to num layers.
    net_dict["encoder"]["from"] = ["lstm%i_fw" % (num_lstm_layers - 1), "lstm%i_bw" % (num_lstm_layers - 1)]
    # Delete non-used lstm layers. This is not explicitly necessary but maybe nicer.
    for i in range(num_lstm_layers, orig_num_lstm_layers):
        del net_dict["lstm%i_fw" % i]
        del net_dict["lstm%i_bw" % i]
        del net_dict["lstm%i_pool" % (i - 1)]
    # Thus we have layers 0 .. (num_lstm_layers - 1).
    layer_idxs = list(range(0, num_lstm_layers))
    layers = ["lstm%i_fw" % i for i in layer_idxs] + ["lstm%i_bw" % i for i in layer_idxs]
    grow_frac = 1.0 - float(orig_num_lstm_layers - num_lstm_layers) / (orig_num_lstm_layers - StartNumLayers)
    dim_frac = InitialDimFactor + (1.0 - InitialDimFactor) * grow_frac
    for layer in layers:
        net_dict[layer]["n_out"] = int(net_dict[layer]["n_out"] * dim_frac)
        if "dropout" in net_dict[layer]:
            net_dict[layer]["dropout"] *= dim_frac
    net_dict["enc_value"]["dims"] = (AttNumHeads, int(EncValuePerHeadDim * dim_frac * 0.5) * 2)
    # Use label smoothing only at the very end.
    if 'loss_opts' in net_dict["output"]["unit"]["output_prob"] and \
            'label_smoothing' in net_dict["output"]["unit"]["output_prob"]["loss_opts"]:
        net_dict["output"]["unit"]["output_prob"]["loss_opts"]["label_smoothing"] = 0
    
    return net_dict




import os
if not os.path.exists(model+".254.index"):
  import shutil
  for ending in [".index", ".meta", ".data-00000-of-00001"]:
    shutil.copyfile("/work/asr4/zeineldeen/setups-data/librispeech/2021-04-23--long-train/work/crnn/training/CRNNTrainingJob.hLLldrjunwA2/output/models/epoch.254"+ending, model+".254"+ending)

